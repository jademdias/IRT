{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tri_jade",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlYn9ijkdq_v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e667d7fd-d667-4d33-a19a-71ec49003084"
      },
      "source": [
        " !R"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "> ^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMeIjz3b-kU5"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import keras\n",
        "from PIL import Image\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfs1i98T-nSh"
      },
      "source": [
        "names = [\"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
        "         \"Naive Bayes\", \"QDA\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2dUnN99-pbB"
      },
      "source": [
        "classifiers = [\n",
        "    DecisionTreeClassifier(max_depth=5),\n",
        "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
        "    MLPClassifier(alpha=1, max_iter=1000),\n",
        "    AdaBoostClassifier(),\n",
        "    GaussianNB(),\n",
        "    QuadraticDiscriminantAnalysis()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auhNXW7W-t1J"
      },
      "source": [
        "def add_noise(img):\n",
        "    '''Add random noise to an image'''\n",
        "    VARIABILITY = 10\n",
        "    deviation = VARIABILITY*random.random()\n",
        "    noise = np.random.normal(0, deviation, img.shape)\n",
        "    img += noise\n",
        "    np.clip(img, 0., 255.)\n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fz9Hm449-yOx"
      },
      "source": [
        "def GenerateDatanoise(X_train_idx):\n",
        "  # Prepare data-augmenting data generator\n",
        "  from keras.preprocessing.image import ImageDataGenerator\n",
        "  datagen = ImageDataGenerator(\n",
        "          rescale=1./255,\n",
        "          rotation_range=20,\n",
        "          width_shift_range=0.1,\n",
        "          height_shift_range=0.1,\n",
        "          zoom_range=0.1,\n",
        "          preprocessing_function=add_noise,\n",
        "      )\n",
        "  # Load a single image as our example\n",
        "  from keras.preprocessing import image\n",
        "  img = X_train_idx\n",
        "\n",
        "  # Generate distorted images\n",
        "  images = [img]\n",
        "  img_arr = image.img_to_array(img)\n",
        "  img_arr = img_arr.reshape((1,) + img_arr.shape)\n",
        "  for batch in datagen.flow(img_arr, batch_size=1):\n",
        "      images.append( image.array_to_img(batch[0]) )\n",
        "      if len(images) >= 1000:\n",
        "          break\n",
        "  return images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20MHvt-c-3QZ"
      },
      "source": [
        "def Aumentarexemplos(X_train, y_train, X_test, y_test):\n",
        "  idxmais = [5397]\n",
        "  for j in idxmais:\n",
        "    #idxmais = 5   \n",
        "    datanoise = GenerateDatanoise(X_test[j])\n",
        "    for i in range(0, len(datanoise)):\n",
        "      X_train = np.append(X_train, [np.array(datanoise[i])], axis=0)\n",
        "      y_train = np.append(y_train, y_train[j])\n",
        "\n",
        "  print(\"X_train shape\", X_train.shape)\n",
        "  print(\"y_train shape\", y_train.shape)\n",
        "  print(\"X_test shape\", X_test.shape)\n",
        "  print(\"y_test shape\", y_test.shape)\n",
        "\n",
        "  return (X_train, y_train), (X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C04rM12HFB6s"
      },
      "source": [
        "def Reduzirclasses(class1, class2, X_train, y_train, X_test, y_test):\n",
        "  for digit in range(0,10):\n",
        "    if (digit != class1) and (digit != class2):\n",
        "      ind_class = np.where(y_train == digit)\n",
        "      y_train = np.delete(y_train, ind_class)\n",
        "      X_train = np.delete(X_train, ind_class, axis = 0)\n",
        "\n",
        "      ind_class_test = np.where(y_test == digit)\n",
        "      y_test = np.delete(y_test, ind_class_test)\n",
        "      X_test = np.delete(X_test, ind_class_test, axis = 0)\n",
        "\n",
        "  print(\"X_train shape\", X_train.shape)\n",
        "  print(\"y_train shape\", y_train.shape)\n",
        "  print(\"X_test shape\", X_test.shape)\n",
        "  print(\"y_test shape\", y_test.shape)\n",
        "\n",
        "  return (X_train, y_train), (X_test, y_test) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xY6m5jnd-6_x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0ae057d-18ef-4fb5-ee10-5feaf4577f07"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels)  = fashion_mnist.load_data()\n",
        "#Exemplos Distantes\n",
        "#class1 = 2\n",
        "#class2 = 7\n",
        "#Exemplos Pr√≥ximos\n",
        "class1 = 2\n",
        "class2 = 4\n",
        "\n",
        "#(train_images, train_labels), (test_images, test_labels)   = Reduzirclasses(class1, class2, train_images, train_labels, test_images, test_labels)\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels)  = Aumentarexemplos(train_images, train_labels, test_images, test_labels)\n",
        "\n",
        "n_X_train = len(train_images)\n",
        "n_X_test = len(test_images)\n",
        "\n",
        "train_images = train_images.reshape(n_X_train, 784)\n",
        "test_images = test_images.reshape(n_X_test, 784)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape (61000, 28, 28)\n",
            "y_train shape (61000,)\n",
            "X_test shape (10000, 28, 28)\n",
            "y_test shape (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8nYqk7n_BGx",
        "outputId": "f6330877-db0c-4fb8-da81-e42ebcf4a218"
      },
      "source": [
        "scores = []\n",
        "for name, clf in zip(names, classifiers):\n",
        "  clf.fit(train_images, train_labels)\n",
        "  score = clf.score(test_images, test_labels)\n",
        "  print(\"Score \", name, \": \", score)\n",
        "  scores.append(score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score  Decision Tree :  0.6944\n",
            "Score  Random Forest :  0.6985\n",
            "Score  Neural Net :  0.8514\n",
            "Score  AdaBoost :  0.5676\n",
            "Score  Naive Bayes :  0.5639\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Score  QDA :  0.5677\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U1pBC8__FMR"
      },
      "source": [
        "pred1 = classifiers[0].predict(test_images)\n",
        "pred2 = classifiers[1].predict(test_images)\n",
        "pred3 = classifiers[2].predict(test_images)\n",
        "pred4 = classifiers[3].predict(test_images)\n",
        "pred5 = classifiers[4].predict(test_images)\n",
        "pred6 = classifiers[5].predict(test_images)\n",
        "\n",
        "predictions = [pred1, pred2, pred3, pred4, pred5, pred6]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JLmnIpN-z0P",
        "outputId": "f440ad6c-7d98-4000-b3ab-6e987910e61e"
      },
      "source": [
        "#Escolha aleat√≥ria de 100 imagens para cada label. (PARA 10 CLASSES)\n",
        "ind_random =[]\n",
        "for digit in range(0, 10):\n",
        "  ind_class = np.where(test_labels == digit)\n",
        "  np.random.shuffle(ind_class[0])\n",
        "  ind_random.append(ind_class[0][1:101])\n",
        "\n",
        "idx = []\n",
        "num_classes = 10\n",
        "for i in range(num_classes):\n",
        "  for j in range(100):\n",
        "    idx.append(ind_random[i][j])\n",
        "print(idx)\n",
        "print('a')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[8197, 1483, 1203, 7158, 7787, 3115, 2420, 9815, 4690, 8350, 2524, 4424, 951, 7626, 9764, 7127, 2968, 3729, 8029, 4206, 8948, 5129, 2872, 7749, 2638, 3557, 6847, 9748, 6972, 1572, 2829, 7774, 9508, 2374, 7940, 858, 9686, 1169, 8815, 2308, 3831, 6293, 9371, 7413, 9809, 7864, 2512, 7824, 6929, 2286, 965, 2047, 2652, 4818, 8564, 6225, 5296, 8851, 8689, 3065, 7623, 8812, 9494, 2506, 1000, 8091, 1948, 3356, 910, 5876, 9061, 6074, 6760, 8031, 7117, 7585, 636, 889, 6065, 1270, 8394, 9021, 6572, 5307, 577, 8657, 2393, 5577, 1403, 5718, 3819, 4121, 9981, 5246, 8168, 8324, 275, 3277, 374, 9342, 7744, 2771, 8535, 2254, 2342, 2643, 3965, 9310, 4974, 4780, 8400, 2729, 4321, 216, 2534, 7150, 1242, 604, 3840, 6125, 6319, 334, 179, 8768, 4452, 7423, 5127, 5812, 6117, 2770, 6053, 2612, 3627, 3597, 2835, 7666, 1664, 3654, 1319, 6336, 5175, 9994, 2640, 4633, 6401, 6100, 8679, 9818, 7808, 9103, 3079, 8539, 9666, 6935, 7693, 5753, 6045, 886, 6080, 8107, 6974, 3000, 4476, 1800, 4482, 2497, 8164, 8200, 660, 5323, 4008, 849, 7920, 8156, 5538, 7184, 2518, 5545, 6415, 2414, 9525, 8228, 4630, 8908, 3561, 7276, 1860, 8064, 9098, 5845, 6763, 8133, 5639, 1219, 3243, 6161, 5843, 4445, 8861, 8053, 4091, 7926, 2208, 4847, 5383, 7810, 4239, 3288, 5713, 4588, 8662, 9784, 3918, 7490, 8498, 5751, 2030, 7452, 3278, 4671, 2547, 16, 9881, 6625, 3726, 9600, 2315, 3164, 5715, 5125, 2601, 7230, 1533, 255, 6885, 4203, 7958, 1361, 9329, 5820, 608, 6243, 1538, 9172, 5647, 9604, 4160, 7283, 2977, 4260, 5250, 668, 9259, 4363, 2908, 2650, 3563, 841, 8500, 3255, 1661, 6459, 4598, 4037, 1042, 1279, 7639, 3365, 9706, 8595, 7753, 6852, 72, 5775, 3394, 2272, 5696, 1926, 4873, 4323, 6237, 4255, 367, 8912, 4196, 5527, 1192, 2337, 457, 4465, 6627, 7633, 6486, 6439, 9746, 8362, 2636, 5075, 2081, 6291, 6583, 931, 9225, 5610, 3722, 9838, 8983, 3833, 9271, 7565, 8928, 3973, 9102, 5664, 7635, 4084, 91, 1801, 271, 2688, 8008, 4491, 7769, 7267, 1920, 4005, 8896, 2312, 9554, 7827, 2256, 9260, 7429, 4915, 9984, 8836, 1631, 3407, 539, 5085, 3007, 7088, 1653, 7681, 466, 1150, 4415, 8864, 2666, 3945, 6748, 376, 2715, 7364, 1968, 1489, 5361, 1047, 2475, 5145, 4435, 4544, 8141, 6354, 698, 1834, 5967, 4667, 3936, 6377, 6907, 1057, 1897, 8377, 5562, 1022, 7264, 6154, 450, 5855, 7587, 8741, 7405, 7415, 6891, 1844, 3795, 1311, 5179, 2844, 7628, 1585, 2695, 2784, 7322, 6423, 8489, 2012, 3616, 1001, 3584, 540, 8140, 4905, 5496, 7594, 1879, 967, 5310, 2462, 1792, 649, 1679, 279, 2737, 9496, 4417, 4464, 2671, 4393, 6751, 1385, 9062, 6908, 6148, 875, 3672, 5774, 2679, 57, 9702, 9643, 6801, 363, 168, 1074, 928, 7642, 2681, 8944, 9040, 10, 6837, 2901, 210, 2273, 153, 3195, 8100, 432, 987, 4095, 1185, 9750, 1077, 1251, 5993, 4373, 3849, 2150, 1132, 1312, 935, 4627, 4096, 2992, 8580, 3430, 3811, 2244, 7965, 637, 3447, 8712, 8891, 1142, 7228, 5124, 5583, 1050, 5397, 3295, 7736, 8104, 8330, 8730, 7110, 8116, 3643, 7991, 4589, 6270, 1362, 7986, 1172, 4739, 6500, 4995, 1075, 1611, 3566, 2103, 1325, 2714, 4171, 8113, 4815, 1092, 3662, 7484, 9213, 8026, 8463, 9760, 7293, 6947, 7768, 6147, 323, 3696, 1776, 7861, 292, 9216, 7027, 6244, 5215, 5290, 8230, 6550, 9374, 1770, 5681, 6945, 690, 7380, 6123, 9629, 8419, 5431, 3893, 502, 7889, 7776, 3618, 1727, 9324, 2183, 7409, 5152, 9941, 2238, 6060, 288, 5451, 3547, 2833, 654, 7074, 7197, 6634, 4843, 3200, 7844, 535, 7206, 6791, 4360, 6194, 9922, 4181, 6979, 4717, 4022, 4076, 4090, 8170, 9375, 9754, 4254, 1435, 2305, 2223, 5781, 1829, 9581, 2748, 2080, 8473, 4888, 8103, 3594, 3645, 5703, 7867, 852, 8240, 1637, 6727, 9099, 5569, 6364, 3165, 684, 3959, 9868, 8940, 9146, 9057, 1940, 9961, 4994, 2009, 5654, 285, 7112, 6322, 4677, 7111, 5410, 3020, 9513, 1277, 4909, 7881, 7012, 7962, 344, 622, 9684, 5990, 9573, 7840, 5452, 3203, 761, 4420, 8995, 9094, 634, 716, 1174, 7903, 966, 322, 226, 5052, 9957, 2459, 2588, 7764, 725, 4152, 7538, 2551, 7296, 4083, 1796, 7004, 5169, 7258, 8769, 8974, 8349, 8664, 2708, 9097, 5571, 6876, 8005, 2247, 7222, 5977, 3257, 7024, 561, 3724, 6663, 193, 3470, 5254, 4941, 5589, 8658, 4082, 9487, 9004, 3347, 1756, 6384, 6206, 8538, 1629, 7303, 9206, 6540, 9831, 9690, 5329, 5378, 4580, 9125, 4634, 230, 2410, 712, 9401, 9197, 3949, 6686, 7783, 3550, 6385, 927, 5050, 4681, 9262, 3498, 3825, 503, 351, 8817, 6779, 1382, 5723, 6792, 7580, 8181, 5045, 1795, 8562, 4773, 4101, 336, 6698, 7923, 1323, 8808, 7759, 5414, 4528, 5944, 7120, 7919, 3030, 5988, 3274, 6490, 4560, 3630, 8493, 6713, 5447, 8520, 2242, 7885, 9860, 8318, 5178, 5861, 6431, 7242, 9044, 5302, 5208, 6209, 402, 7960, 6836, 6534, 6680, 6719, 6677, 1534, 3378, 5353, 43, 8391, 4117, 4330, 8325, 9144, 3538, 7728, 8553, 4999, 6814, 901, 9266, 5868, 1915, 6482, 3136, 8700, 6541, 1956, 5846, 2077, 1089, 3559, 2304, 3468, 5784, 3189, 4341, 4805, 6443, 2389, 9301, 7168, 5838, 3709, 6536, 5403, 6410, 8287, 5147, 8844, 5390, 9022, 2561, 9007, 3376, 7689, 5376, 9321, 2000, 7340, 1737, 4844, 1455, 7513, 5717, 8070, 2799, 429, 9108, 4232, 8904, 6930, 2947, 929, 9226, 8446, 882, 8321, 1751, 1126, 9549, 1406, 3242, 7091, 220, 9741, 5122, 8547, 1470, 7480, 8188, 9992, 1884, 4989, 6522, 8286, 424, 533, 126, 3757, 5658, 529, 5430, 2557, 3814, 4026, 5402, 6403, 2005, 1845, 1846, 4436, 5217, 3354, 9234, 5470, 9096, 116, 9642, 1427, 9923, 642, 7927, 7269, 1715, 6421, 3869, 9636, 2027, 3725, 9533, 3680, 7860, 268, 5101, 3314, 8504, 6359, 5077, 7644, 6984, 2520, 3721, 4296, 9370, 8922, 9759, 980, 1133, 4614, 5890, 7658, 3395, 7010, 9915, 2250, 556, 6769, 5009, 1709, 5989, 5560, 810, 8460, 1141, 6029, 5439, 4830, 7113, 9083, 2494, 1962, 1418, 5553, 122, 3308, 5891, 1068, 9058, 9739, 9139, 2187, 6017, 4997, 7145, 2488, 8398, 6733, 2768, 1894, 680, 9053, 5111, 4044, 2113, 3834, 7865, 5975, 6537, 5600, 9757, 9978, 4631, 6267, 4450, 5019, 4002, 2056, 3477, 9175, 3408, 7044, 7902, 2935, 7099, 1505, 5938, 1522, 6552, 9526, 23, 683, 7378, 9614, 6005, 1544, 4369, 8479, 5314, 9964, 5102, 6130]\n",
            "a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yco6fmTGIaUn"
      },
      "source": [
        "#Escolha aleat√≥ria de 100 imagens para cada label. (PARA 2 CLASSES)\n",
        "ind_random =[]\n",
        "labels_distantes = [2, 7]\n",
        "labels_proximos = [2, 4]\n",
        "for digit in labels_proximos:\n",
        "  ind_class = np.where(test_labels == digit)\n",
        "  np.random.shuffle(ind_class[0])\n",
        "  ind_random.append(ind_class[0][1:101])\n",
        "\n",
        "idx = []\n",
        "num_classes = 2\n",
        "for i in range(num_classes):\n",
        "  for j in range(100):\n",
        "   idx.append(ind_random[i][j])\n",
        "print(idx)\n",
        "print(len(idx))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEmpBzY381FZ"
      },
      "source": [
        "idx= [8197, 1483, 1203, 7158, 7787, 3115, 2420, 9815, 4690, 8350, 2524, 4424, 951, 7626, 9764, 7127, 2968, 3729, 8029, 4206, 8948, 5129, 2872, 7749, 2638, 3557, 6847, 9748, 6972, 1572, 2829, 7774, 9508, 2374, 7940, 858, 9686, 1169, 8815, 2308, 3831, 6293, 9371, 7413, 9809, 7864, 2512, 7824, 6929, 2286, 965, 2047, 2652, 4818, 8564, 6225, 5296, 8851, 8689, 3065, 7623, 8812, 9494, 2506, 1000, 8091, 1948, 3356, 910, 5876, 9061, 6074, 6760, 8031, 7117, 7585, 636, 889, 6065, 1270, 8394, 9021, 6572, 5307, 577, 8657, 2393, 5577, 1403, 5718, 3819, 4121, 9981, 5246, 8168, 8324, 275, 3277, 374, 9342, 7744, 2771, 8535, 2254, 2342, 2643, 3965, 9310, 4974, 4780, 8400, 2729, 4321, 216, 2534, 7150, 1242, 604, 3840, 6125, 6319, 334, 179, 8768, 4452, 7423, 5127, 5812, 6117, 2770, 6053, 2612, 3627, 3597, 2835, 7666, 1664, 3654, 1319, 6336, 5175, 9994, 2640, 4633, 6401, 6100, 8679, 9818, 7808, 9103, 3079, 8539, 9666, 6935, 7693, 5753, 6045, 886, 6080, 8107, 6974, 3000, 4476, 1800, 4482, 2497, 8164, 8200, 660, 5323, 4008, 849, 7920, 8156, 5538, 7184, 2518, 5545, 6415, 2414, 9525, 8228, 4630, 8908, 3561, 7276, 1860, 8064, 9098, 5845, 6763, 8133, 5639, 1219, 3243, 6161, 5843, 4445, 8861, 8053, 4091, 7926, 2208, 4847, 5383, 7810, 4239, 3288, 5713, 4588, 8662, 9784, 3918, 7490, 8498, 5751, 2030, 7452, 3278, 4671, 2547, 16, 9881, 6625, 3726, 9600, 2315, 3164, 5715, 5125, 2601, 7230, 1533, 255, 6885, 4203, 7958, 1361, 9329, 5820, 608, 6243, 1538, 9172, 5647, 9604, 4160, 7283, 2977, 4260, 5250, 668, 9259, 4363, 2908, 2650, 3563, 841, 8500, 3255, 1661, 6459, 4598, 4037, 1042, 1279, 7639, 3365, 9706, 8595, 7753, 6852, 72, 5775, 3394, 2272, 5696, 1926, 4873, 4323, 6237, 4255, 367, 8912, 4196, 5527, 1192, 2337, 457, 4465, 6627, 7633, 6486, 6439, 9746, 8362, 2636, 5075, 2081, 6291, 6583, 931, 9225, 5610, 3722, 9838, 8983, 3833, 9271, 7565, 8928, 3973, 9102, 5664, 7635, 4084, 91, 1801, 271, 2688, 8008, 4491, 7769, 7267, 1920, 4005, 8896, 2312, 9554, 7827, 2256, 9260, 7429, 4915, 9984, 8836, 1631, 3407, 539, 5085, 3007, 7088, 1653, 7681, 466, 1150, 4415, 8864, 2666, 3945, 6748, 376, 2715, 7364, 1968, 1489, 5361, 1047, 2475, 5145, 4435, 4544, 8141, 6354, 698, 1834, 5967, 4667, 3936, 6377, 6907, 1057, 1897, 8377, 5562, 1022, 7264, 6154, 450, 5855, 7587, 8741, 7405, 7415, 6891, 1844, 3795, 1311, 5179, 2844, 7628, 1585, 2695, 2784, 7322, 6423, 8489, 2012, 3616, 1001, 3584, 540, 8140, 4905, 5496, 7594, 1879, 967, 5310, 2462, 1792, 649, 1679, 279, 2737, 9496, 4417, 4464, 2671, 4393, 6751, 1385, 9062, 6908, 6148, 875, 3672, 5774, 2679, 57, 9702, 9643, 6801, 363, 168, 1074, 928, 7642, 2681, 8944, 9040, 10, 6837, 2901, 210, 2273, 153, 3195, 8100, 432, 987, 4095, 1185, 9750, 1077, 1251, 5993, 4373, 3849, 2150, 1132, 1312, 935, 4627, 4096, 2992, 8580, 3430, 3811, 2244, 7965, 637, 3447, 8712, 8891, 1142, 7228, 5124, 5583, 1050, 5397, 3295, 7736, 8104, 8330, 8730, 7110, 8116, 3643, 7991, 4589, 6270, 1362, 7986, 1172, 4739, 6500, 4995, 1075, 1611, 3566, 2103, 1325, 2714, 4171, 8113, 4815, 1092, 3662, 7484, 9213, 8026, 8463, 9760, 7293, 6947, 7768, 6147, 323, 3696, 1776, 7861, 292, 9216, 7027, 6244, 5215, 5290, 8230, 6550, 9374, 1770, 5681, 6945, 690, 7380, 6123, 9629, 8419, 5431, 3893, 502, 7889, 7776, 3618, 1727, 9324, 2183, 7409, 5152, 9941, 2238, 6060, 288, 5451, 3547, 2833, 654, 7074, 7197, 6634, 4843, 3200, 7844, 535, 7206, 6791, 4360, 6194, 9922, 4181, 6979, 4717, 4022, 4076, 4090, 8170, 9375, 9754, 4254, 1435, 2305, 2223, 5781, 1829, 9581, 2748, 2080, 8473, 4888, 8103, 3594, 3645, 5703, 7867, 852, 8240, 1637, 6727, 9099, 5569, 6364, 3165, 684, 3959, 9868, 8940, 9146, 9057, 1940, 9961, 4994, 2009, 5654, 285, 7112, 6322, 4677, 7111, 5410, 3020, 9513, 1277, 4909, 7881, 7012, 7962, 344, 622, 9684, 5990, 9573, 7840, 5452, 3203, 761, 4420, 8995, 9094, 634, 716, 1174, 7903, 966, 322, 226, 5052, 9957, 2459, 2588, 7764, 725, 4152, 7538, 2551, 7296, 4083, 1796, 7004, 5169, 7258, 8769, 8974, 8349, 8664, 2708, 9097, 5571, 6876, 8005, 2247, 7222, 5977, 3257, 7024, 561, 3724, 6663, 193, 3470, 5254, 4941, 5589, 8658, 4082, 9487, 9004, 3347, 1756, 6384, 6206, 8538, 1629, 7303, 9206, 6540, 9831, 9690, 5329, 5378, 4580, 9125, 4634, 230, 2410, 712, 9401, 9197, 3949, 6686, 7783, 3550, 6385, 927, 5050, 4681, 9262, 3498, 3825, 503, 351, 8817, 6779, 1382, 5723, 6792, 7580, 8181, 5045, 1795, 8562, 4773, 4101, 336, 6698, 7923, 1323, 8808, 7759, 5414, 4528, 5944, 7120, 7919, 3030, 5988, 3274, 6490, 4560, 3630, 8493, 6713, 5447, 8520, 2242, 7885, 9860, 8318, 5178, 5861, 6431, 7242, 9044, 5302, 5208, 6209, 402, 7960, 6836, 6534, 6680, 6719, 6677, 1534, 3378, 5353, 43, 8391, 4117, 4330, 8325, 9144, 3538, 7728, 8553, 4999, 6814, 901, 9266, 5868, 1915, 6482, 3136, 8700, 6541, 1956, 5846, 2077, 1089, 3559, 2304, 3468, 5784, 3189, 4341, 4805, 6443, 2389, 9301, 7168, 5838, 3709, 6536, 5403, 6410, 8287, 5147, 8844, 5390, 9022, 2561, 9007, 3376, 7689, 5376, 9321, 2000, 7340, 1737, 4844, 1455, 7513, 5717, 8070, 2799, 429, 9108, 4232, 8904, 6930, 2947, 929, 9226, 8446, 882, 8321, 1751, 1126, 9549, 1406, 3242, 7091, 220, 9741, 5122, 8547, 1470, 7480, 8188, 9992, 1884, 4989, 6522, 8286, 424, 533, 126, 3757, 5658, 529, 5430, 2557, 3814, 4026, 5402, 6403, 2005, 1845, 1846, 4436, 5217, 3354, 9234, 5470, 9096, 116, 9642, 1427, 9923, 642, 7927, 7269, 1715, 6421, 3869, 9636, 2027, 3725, 9533, 3680, 7860, 268, 5101, 3314, 8504, 6359, 5077, 7644, 6984, 2520, 3721, 4296, 9370, 8922, 9759, 980, 1133, 4614, 5890, 7658, 3395, 7010, 9915, 2250, 556, 6769, 5009, 1709, 5989, 5560, 810, 8460, 1141, 6029, 5439, 4830, 7113, 9083, 2494, 1962, 1418, 5553, 122, 3308, 5891, 1068, 9058, 9739, 9139, 2187, 6017, 4997, 7145, 2488, 8398, 6733, 2768, 1894, 680, 9053, 5111, 4044, 2113, 3834, 7865, 5975, 6537, 5600, 9757, 9978, 4631, 6267, 4450, 5019, 4002, 2056, 3477, 9175, 3408, 7044, 7902, 2935, 7099, 1505, 5938, 1522, 6552, 9526, 23, 683, 7378, 9614, 6005, 1544, 4369, 8479, 5314, 9964, 5102, 6130]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4m4rbFkF_JjC"
      },
      "source": [
        "#Escolha aleat√≥ria de 100 imagens para cada label (2 classes = 200 idx)\n",
        "#distantes\n",
        "#idx = [682, 517, 427, 89, 501, 1593, 279, 1585, 1044, 433, 129, 1245, 580, 618, 1270, 347, 1558, 1799, 564, 269, 838, 1146, 944, 1827, 1844, 689, 1198, 97, 270, 1553, 1111, 213, 823, 382, 110, 1865, 1417, 1936, 1986, 885, 1670, 669, 907, 1135, 1744, 271, 83, 63, 995, 755, 34, 1058, 929, 1179, 496, 1391, 1649, 709, 1796, 1447, 692, 1780, 226, 1763, 1579, 622, 1390, 1345, 1628, 581, 1143, 1847, 118, 1898, 510, 1186, 411, 1038, 1067, 441, 95, 491, 1998, 1990, 196, 1250, 1830, 1342, 749, 1672, 432, 1458, 404, 146, 1671, 1532, 357, 1164, 531, 650, 381, 702, 1551, 543, 690, 900, 1088, 539, 420, 1712, 557, 1057, 163, 352, 1846, 839, 582, 1029, 1282, 1610, 1683, 284, 332, 1149, 635, 350, 1769, 323, 1838, 16, 1008, 326, 455, 1448, 1915, 1828, 1414, 85, 1906, 154, 1061, 189, 1274, 520, 1337, 545, 416, 1225, 977, 1520, 1662, 1682, 1788, 1123, 1573, 1354, 1352, 1094, 1297, 1110, 1705, 452, 69, 1228, 745, 1639, 1389, 1816, 533, 911, 397, 1176, 1924, 1582, 487, 1702, 1372, 406, 731, 760, 976, 159, 1789, 318, 619, 1247, 145, 1782, 243, 1633, 1891, 139, 558, 762, 1836, 903, 688, 563, 1962, 846]\n",
        "#pr√≥ximos\n",
        "idx = [725, 1683, 1424, 1708, 1334, 1930, 122, 1776, 1446, 1707, 415, 54, 1737, 445, 278, 885, 1579, 1780, 1063, 674, 1544, 1727, 1862, 745, 1565, 625, 349, 366, 479, 1439, 1154, 1794, 855, 630, 1413, 1427, 1281, 323, 1060, 1920, 1554, 901, 1891, 1169, 487, 1019, 1445, 1151, 452, 917, 528, 1758, 722, 1848, 539, 1403, 1101, 306, 1346, 1201, 1071, 1186, 1469, 1261, 384, 347, 652, 1716, 1000, 1495, 558, 10, 762, 667, 1487, 1481, 886, 1606, 1752, 453, 1310, 1393, 1351, 1476, 875, 1355, 56, 1950, 365, 1454, 1957, 1945, 1142, 657, 1566, 663, 668, 1893, 1237, 636, 1079, 899, 1985, 39, 1724, 533, 936, 1983, 260, 1250, 1400, 1248, 1688, 593, 483, 591, 1798, 1881, 1179, 971, 1466, 1200, 1618, 1593, 345, 397, 631, 906, 1592, 1236, 1022, 1027, 575, 847, 1615, 190, 817, 423, 1141, 1116, 687, 570, 1189, 1190, 500, 336, 371, 22, 1590, 545, 499, 140, 627, 916, 1388, 85, 1329, 523, 1373, 1150, 460, 289, 502, 135, 1754, 1651, 1024, 276, 1354, 793, 1702, 1885, 1067, 1382, 409, 717, 585, 1028, 35, 1068, 1490, 1110, 951, 372, 938, 747, 1807, 1280, 1091, 253, 1499, 1399, 1489, 1340, 442, 800, 1577, 1946, 1879, 1402]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8e9UH9W_NgS",
        "outputId": "f067c71f-c189-4081-8a40-ad3f11773b1e"
      },
      "source": [
        "resultado = []\n",
        "for pred in predictions:\n",
        "  labels = []\n",
        "  preds = []\n",
        "  for i in idx: \n",
        "    labels.append(test_labels[i])\n",
        "    preds.append(pred[i])\n",
        "  res = []\n",
        "  for i, j in zip(labels, preds):\n",
        "    if(i == j):\n",
        "      z = 1\n",
        "    else:\n",
        "      z = 0\n",
        "    res.append(z)\n",
        "  resultado.append(res)\n",
        "print(resultado[4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQBCJuqs_Tjv",
        "outputId": "0fd1a9ec-3e9b-45d5-d777-97ba1883a739"
      },
      "source": [
        "colunas = []\n",
        "nitens = 1000 \n",
        "for i in range(1, nitens+1):\n",
        "  colunas.append(\"Item.\"+ str(i))\n",
        "print(colunas)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Item.1', 'Item.2', 'Item.3', 'Item.4', 'Item.5', 'Item.6', 'Item.7', 'Item.8', 'Item.9', 'Item.10', 'Item.11', 'Item.12', 'Item.13', 'Item.14', 'Item.15', 'Item.16', 'Item.17', 'Item.18', 'Item.19', 'Item.20', 'Item.21', 'Item.22', 'Item.23', 'Item.24', 'Item.25', 'Item.26', 'Item.27', 'Item.28', 'Item.29', 'Item.30', 'Item.31', 'Item.32', 'Item.33', 'Item.34', 'Item.35', 'Item.36', 'Item.37', 'Item.38', 'Item.39', 'Item.40', 'Item.41', 'Item.42', 'Item.43', 'Item.44', 'Item.45', 'Item.46', 'Item.47', 'Item.48', 'Item.49', 'Item.50', 'Item.51', 'Item.52', 'Item.53', 'Item.54', 'Item.55', 'Item.56', 'Item.57', 'Item.58', 'Item.59', 'Item.60', 'Item.61', 'Item.62', 'Item.63', 'Item.64', 'Item.65', 'Item.66', 'Item.67', 'Item.68', 'Item.69', 'Item.70', 'Item.71', 'Item.72', 'Item.73', 'Item.74', 'Item.75', 'Item.76', 'Item.77', 'Item.78', 'Item.79', 'Item.80', 'Item.81', 'Item.82', 'Item.83', 'Item.84', 'Item.85', 'Item.86', 'Item.87', 'Item.88', 'Item.89', 'Item.90', 'Item.91', 'Item.92', 'Item.93', 'Item.94', 'Item.95', 'Item.96', 'Item.97', 'Item.98', 'Item.99', 'Item.100', 'Item.101', 'Item.102', 'Item.103', 'Item.104', 'Item.105', 'Item.106', 'Item.107', 'Item.108', 'Item.109', 'Item.110', 'Item.111', 'Item.112', 'Item.113', 'Item.114', 'Item.115', 'Item.116', 'Item.117', 'Item.118', 'Item.119', 'Item.120', 'Item.121', 'Item.122', 'Item.123', 'Item.124', 'Item.125', 'Item.126', 'Item.127', 'Item.128', 'Item.129', 'Item.130', 'Item.131', 'Item.132', 'Item.133', 'Item.134', 'Item.135', 'Item.136', 'Item.137', 'Item.138', 'Item.139', 'Item.140', 'Item.141', 'Item.142', 'Item.143', 'Item.144', 'Item.145', 'Item.146', 'Item.147', 'Item.148', 'Item.149', 'Item.150', 'Item.151', 'Item.152', 'Item.153', 'Item.154', 'Item.155', 'Item.156', 'Item.157', 'Item.158', 'Item.159', 'Item.160', 'Item.161', 'Item.162', 'Item.163', 'Item.164', 'Item.165', 'Item.166', 'Item.167', 'Item.168', 'Item.169', 'Item.170', 'Item.171', 'Item.172', 'Item.173', 'Item.174', 'Item.175', 'Item.176', 'Item.177', 'Item.178', 'Item.179', 'Item.180', 'Item.181', 'Item.182', 'Item.183', 'Item.184', 'Item.185', 'Item.186', 'Item.187', 'Item.188', 'Item.189', 'Item.190', 'Item.191', 'Item.192', 'Item.193', 'Item.194', 'Item.195', 'Item.196', 'Item.197', 'Item.198', 'Item.199', 'Item.200', 'Item.201', 'Item.202', 'Item.203', 'Item.204', 'Item.205', 'Item.206', 'Item.207', 'Item.208', 'Item.209', 'Item.210', 'Item.211', 'Item.212', 'Item.213', 'Item.214', 'Item.215', 'Item.216', 'Item.217', 'Item.218', 'Item.219', 'Item.220', 'Item.221', 'Item.222', 'Item.223', 'Item.224', 'Item.225', 'Item.226', 'Item.227', 'Item.228', 'Item.229', 'Item.230', 'Item.231', 'Item.232', 'Item.233', 'Item.234', 'Item.235', 'Item.236', 'Item.237', 'Item.238', 'Item.239', 'Item.240', 'Item.241', 'Item.242', 'Item.243', 'Item.244', 'Item.245', 'Item.246', 'Item.247', 'Item.248', 'Item.249', 'Item.250', 'Item.251', 'Item.252', 'Item.253', 'Item.254', 'Item.255', 'Item.256', 'Item.257', 'Item.258', 'Item.259', 'Item.260', 'Item.261', 'Item.262', 'Item.263', 'Item.264', 'Item.265', 'Item.266', 'Item.267', 'Item.268', 'Item.269', 'Item.270', 'Item.271', 'Item.272', 'Item.273', 'Item.274', 'Item.275', 'Item.276', 'Item.277', 'Item.278', 'Item.279', 'Item.280', 'Item.281', 'Item.282', 'Item.283', 'Item.284', 'Item.285', 'Item.286', 'Item.287', 'Item.288', 'Item.289', 'Item.290', 'Item.291', 'Item.292', 'Item.293', 'Item.294', 'Item.295', 'Item.296', 'Item.297', 'Item.298', 'Item.299', 'Item.300', 'Item.301', 'Item.302', 'Item.303', 'Item.304', 'Item.305', 'Item.306', 'Item.307', 'Item.308', 'Item.309', 'Item.310', 'Item.311', 'Item.312', 'Item.313', 'Item.314', 'Item.315', 'Item.316', 'Item.317', 'Item.318', 'Item.319', 'Item.320', 'Item.321', 'Item.322', 'Item.323', 'Item.324', 'Item.325', 'Item.326', 'Item.327', 'Item.328', 'Item.329', 'Item.330', 'Item.331', 'Item.332', 'Item.333', 'Item.334', 'Item.335', 'Item.336', 'Item.337', 'Item.338', 'Item.339', 'Item.340', 'Item.341', 'Item.342', 'Item.343', 'Item.344', 'Item.345', 'Item.346', 'Item.347', 'Item.348', 'Item.349', 'Item.350', 'Item.351', 'Item.352', 'Item.353', 'Item.354', 'Item.355', 'Item.356', 'Item.357', 'Item.358', 'Item.359', 'Item.360', 'Item.361', 'Item.362', 'Item.363', 'Item.364', 'Item.365', 'Item.366', 'Item.367', 'Item.368', 'Item.369', 'Item.370', 'Item.371', 'Item.372', 'Item.373', 'Item.374', 'Item.375', 'Item.376', 'Item.377', 'Item.378', 'Item.379', 'Item.380', 'Item.381', 'Item.382', 'Item.383', 'Item.384', 'Item.385', 'Item.386', 'Item.387', 'Item.388', 'Item.389', 'Item.390', 'Item.391', 'Item.392', 'Item.393', 'Item.394', 'Item.395', 'Item.396', 'Item.397', 'Item.398', 'Item.399', 'Item.400', 'Item.401', 'Item.402', 'Item.403', 'Item.404', 'Item.405', 'Item.406', 'Item.407', 'Item.408', 'Item.409', 'Item.410', 'Item.411', 'Item.412', 'Item.413', 'Item.414', 'Item.415', 'Item.416', 'Item.417', 'Item.418', 'Item.419', 'Item.420', 'Item.421', 'Item.422', 'Item.423', 'Item.424', 'Item.425', 'Item.426', 'Item.427', 'Item.428', 'Item.429', 'Item.430', 'Item.431', 'Item.432', 'Item.433', 'Item.434', 'Item.435', 'Item.436', 'Item.437', 'Item.438', 'Item.439', 'Item.440', 'Item.441', 'Item.442', 'Item.443', 'Item.444', 'Item.445', 'Item.446', 'Item.447', 'Item.448', 'Item.449', 'Item.450', 'Item.451', 'Item.452', 'Item.453', 'Item.454', 'Item.455', 'Item.456', 'Item.457', 'Item.458', 'Item.459', 'Item.460', 'Item.461', 'Item.462', 'Item.463', 'Item.464', 'Item.465', 'Item.466', 'Item.467', 'Item.468', 'Item.469', 'Item.470', 'Item.471', 'Item.472', 'Item.473', 'Item.474', 'Item.475', 'Item.476', 'Item.477', 'Item.478', 'Item.479', 'Item.480', 'Item.481', 'Item.482', 'Item.483', 'Item.484', 'Item.485', 'Item.486', 'Item.487', 'Item.488', 'Item.489', 'Item.490', 'Item.491', 'Item.492', 'Item.493', 'Item.494', 'Item.495', 'Item.496', 'Item.497', 'Item.498', 'Item.499', 'Item.500', 'Item.501', 'Item.502', 'Item.503', 'Item.504', 'Item.505', 'Item.506', 'Item.507', 'Item.508', 'Item.509', 'Item.510', 'Item.511', 'Item.512', 'Item.513', 'Item.514', 'Item.515', 'Item.516', 'Item.517', 'Item.518', 'Item.519', 'Item.520', 'Item.521', 'Item.522', 'Item.523', 'Item.524', 'Item.525', 'Item.526', 'Item.527', 'Item.528', 'Item.529', 'Item.530', 'Item.531', 'Item.532', 'Item.533', 'Item.534', 'Item.535', 'Item.536', 'Item.537', 'Item.538', 'Item.539', 'Item.540', 'Item.541', 'Item.542', 'Item.543', 'Item.544', 'Item.545', 'Item.546', 'Item.547', 'Item.548', 'Item.549', 'Item.550', 'Item.551', 'Item.552', 'Item.553', 'Item.554', 'Item.555', 'Item.556', 'Item.557', 'Item.558', 'Item.559', 'Item.560', 'Item.561', 'Item.562', 'Item.563', 'Item.564', 'Item.565', 'Item.566', 'Item.567', 'Item.568', 'Item.569', 'Item.570', 'Item.571', 'Item.572', 'Item.573', 'Item.574', 'Item.575', 'Item.576', 'Item.577', 'Item.578', 'Item.579', 'Item.580', 'Item.581', 'Item.582', 'Item.583', 'Item.584', 'Item.585', 'Item.586', 'Item.587', 'Item.588', 'Item.589', 'Item.590', 'Item.591', 'Item.592', 'Item.593', 'Item.594', 'Item.595', 'Item.596', 'Item.597', 'Item.598', 'Item.599', 'Item.600', 'Item.601', 'Item.602', 'Item.603', 'Item.604', 'Item.605', 'Item.606', 'Item.607', 'Item.608', 'Item.609', 'Item.610', 'Item.611', 'Item.612', 'Item.613', 'Item.614', 'Item.615', 'Item.616', 'Item.617', 'Item.618', 'Item.619', 'Item.620', 'Item.621', 'Item.622', 'Item.623', 'Item.624', 'Item.625', 'Item.626', 'Item.627', 'Item.628', 'Item.629', 'Item.630', 'Item.631', 'Item.632', 'Item.633', 'Item.634', 'Item.635', 'Item.636', 'Item.637', 'Item.638', 'Item.639', 'Item.640', 'Item.641', 'Item.642', 'Item.643', 'Item.644', 'Item.645', 'Item.646', 'Item.647', 'Item.648', 'Item.649', 'Item.650', 'Item.651', 'Item.652', 'Item.653', 'Item.654', 'Item.655', 'Item.656', 'Item.657', 'Item.658', 'Item.659', 'Item.660', 'Item.661', 'Item.662', 'Item.663', 'Item.664', 'Item.665', 'Item.666', 'Item.667', 'Item.668', 'Item.669', 'Item.670', 'Item.671', 'Item.672', 'Item.673', 'Item.674', 'Item.675', 'Item.676', 'Item.677', 'Item.678', 'Item.679', 'Item.680', 'Item.681', 'Item.682', 'Item.683', 'Item.684', 'Item.685', 'Item.686', 'Item.687', 'Item.688', 'Item.689', 'Item.690', 'Item.691', 'Item.692', 'Item.693', 'Item.694', 'Item.695', 'Item.696', 'Item.697', 'Item.698', 'Item.699', 'Item.700', 'Item.701', 'Item.702', 'Item.703', 'Item.704', 'Item.705', 'Item.706', 'Item.707', 'Item.708', 'Item.709', 'Item.710', 'Item.711', 'Item.712', 'Item.713', 'Item.714', 'Item.715', 'Item.716', 'Item.717', 'Item.718', 'Item.719', 'Item.720', 'Item.721', 'Item.722', 'Item.723', 'Item.724', 'Item.725', 'Item.726', 'Item.727', 'Item.728', 'Item.729', 'Item.730', 'Item.731', 'Item.732', 'Item.733', 'Item.734', 'Item.735', 'Item.736', 'Item.737', 'Item.738', 'Item.739', 'Item.740', 'Item.741', 'Item.742', 'Item.743', 'Item.744', 'Item.745', 'Item.746', 'Item.747', 'Item.748', 'Item.749', 'Item.750', 'Item.751', 'Item.752', 'Item.753', 'Item.754', 'Item.755', 'Item.756', 'Item.757', 'Item.758', 'Item.759', 'Item.760', 'Item.761', 'Item.762', 'Item.763', 'Item.764', 'Item.765', 'Item.766', 'Item.767', 'Item.768', 'Item.769', 'Item.770', 'Item.771', 'Item.772', 'Item.773', 'Item.774', 'Item.775', 'Item.776', 'Item.777', 'Item.778', 'Item.779', 'Item.780', 'Item.781', 'Item.782', 'Item.783', 'Item.784', 'Item.785', 'Item.786', 'Item.787', 'Item.788', 'Item.789', 'Item.790', 'Item.791', 'Item.792', 'Item.793', 'Item.794', 'Item.795', 'Item.796', 'Item.797', 'Item.798', 'Item.799', 'Item.800', 'Item.801', 'Item.802', 'Item.803', 'Item.804', 'Item.805', 'Item.806', 'Item.807', 'Item.808', 'Item.809', 'Item.810', 'Item.811', 'Item.812', 'Item.813', 'Item.814', 'Item.815', 'Item.816', 'Item.817', 'Item.818', 'Item.819', 'Item.820', 'Item.821', 'Item.822', 'Item.823', 'Item.824', 'Item.825', 'Item.826', 'Item.827', 'Item.828', 'Item.829', 'Item.830', 'Item.831', 'Item.832', 'Item.833', 'Item.834', 'Item.835', 'Item.836', 'Item.837', 'Item.838', 'Item.839', 'Item.840', 'Item.841', 'Item.842', 'Item.843', 'Item.844', 'Item.845', 'Item.846', 'Item.847', 'Item.848', 'Item.849', 'Item.850', 'Item.851', 'Item.852', 'Item.853', 'Item.854', 'Item.855', 'Item.856', 'Item.857', 'Item.858', 'Item.859', 'Item.860', 'Item.861', 'Item.862', 'Item.863', 'Item.864', 'Item.865', 'Item.866', 'Item.867', 'Item.868', 'Item.869', 'Item.870', 'Item.871', 'Item.872', 'Item.873', 'Item.874', 'Item.875', 'Item.876', 'Item.877', 'Item.878', 'Item.879', 'Item.880', 'Item.881', 'Item.882', 'Item.883', 'Item.884', 'Item.885', 'Item.886', 'Item.887', 'Item.888', 'Item.889', 'Item.890', 'Item.891', 'Item.892', 'Item.893', 'Item.894', 'Item.895', 'Item.896', 'Item.897', 'Item.898', 'Item.899', 'Item.900', 'Item.901', 'Item.902', 'Item.903', 'Item.904', 'Item.905', 'Item.906', 'Item.907', 'Item.908', 'Item.909', 'Item.910', 'Item.911', 'Item.912', 'Item.913', 'Item.914', 'Item.915', 'Item.916', 'Item.917', 'Item.918', 'Item.919', 'Item.920', 'Item.921', 'Item.922', 'Item.923', 'Item.924', 'Item.925', 'Item.926', 'Item.927', 'Item.928', 'Item.929', 'Item.930', 'Item.931', 'Item.932', 'Item.933', 'Item.934', 'Item.935', 'Item.936', 'Item.937', 'Item.938', 'Item.939', 'Item.940', 'Item.941', 'Item.942', 'Item.943', 'Item.944', 'Item.945', 'Item.946', 'Item.947', 'Item.948', 'Item.949', 'Item.950', 'Item.951', 'Item.952', 'Item.953', 'Item.954', 'Item.955', 'Item.956', 'Item.957', 'Item.958', 'Item.959', 'Item.960', 'Item.961', 'Item.962', 'Item.963', 'Item.964', 'Item.965', 'Item.966', 'Item.967', 'Item.968', 'Item.969', 'Item.970', 'Item.971', 'Item.972', 'Item.973', 'Item.974', 'Item.975', 'Item.976', 'Item.977', 'Item.978', 'Item.979', 'Item.980', 'Item.981', 'Item.982', 'Item.983', 'Item.984', 'Item.985', 'Item.986', 'Item.987', 'Item.988', 'Item.989', 'Item.990', 'Item.991', 'Item.992', 'Item.993', 'Item.994', 'Item.995', 'Item.996', 'Item.997', 'Item.998', 'Item.999', 'Item.1000']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SNagbNR_Y8B",
        "outputId": "89a6ec3a-f381-4ed0-850f-dc7405fb75da"
      },
      "source": [
        "data=[] #certo(1), errado(0)\n",
        "for i in resultado:\n",
        "  data.append(i)\n",
        "\n",
        "df = pd.DataFrame(data, columns = colunas)\n",
        "df.loc[6]=[0]*nitens\n",
        "df.loc[7]=[1]*nitens\n",
        "print(df)\n",
        "df.to_csv('/content/data.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Item.1  Item.2  Item.3  Item.4  ...  Item.997  Item.998  Item.999  Item.1000\n",
            "0       0       0       0       1  ...         1         1         1          1\n",
            "1       1       0       1       1  ...         1         1         1          1\n",
            "2       1       1       1       1  ...         1         1         1          1\n",
            "3       0       0       0       0  ...         0         0         0          1\n",
            "4       0       0       0       0  ...         0         0         1          1\n",
            "5       0       1       0       1  ...         1         1         1          1\n",
            "6       0       0       0       0  ...         0         0         0          0\n",
            "7       1       1       1       1  ...         1         1         1          1\n",
            "\n",
            "[8 rows x 1000 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nek_YEff47h",
        "outputId": "5735f4b8-537b-421e-99de-8863cd5f3ab0"
      },
      "source": [
        "!Rscript tri.txt "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing package into ‚Äò/usr/local/lib/R/site-library‚Äô\n",
            "(as ‚Äòlib‚Äô is unspecified)\n",
            "trying URL 'https://cran.rstudio.com/src/contrib/devtools_2.4.2.tar.gz'\n",
            "Content type 'application/x-gzip' length 371298 bytes (362 KB)\n",
            "==================================================\n",
            "downloaded 362 KB\n",
            "\n",
            "* installing *source* package ‚Äòdevtools‚Äô ...\n",
            "** package ‚Äòdevtools‚Äô successfully unpacked and MD5 sums checked\n",
            "** using staged installation\n",
            "** R\n",
            "** inst\n",
            "** byte-compile and prepare package for lazy loading\n",
            "** help\n",
            "*** installing help indices\n",
            "*** copying figures\n",
            "** building package indices\n",
            "** installing vignettes\n",
            "** testing if installed package can be loaded from temporary location\n",
            "** testing if installed package can be loaded from final location\n",
            "** testing if installed package keeps a record of temporary installation path\n",
            "* DONE (devtools)\n",
            "\n",
            "The downloaded source packages are in\n",
            "\t‚Äò/tmp/RtmpXQavcO/downloaded_packages‚Äô\n",
            "Loading required package: usethis\n",
            "\u001b[?25hSkipping install of 'mirt' from a github remote, the SHA1 (3a6af5e7) has not changed since last install.\n",
            "  Use `force = TRUE` to force installation\n",
            "\u001b[?25hLoading required package: stats4\n",
            "Loading required package: lattice\n",
            "Iteration: 500, Log-Lik: -1453.399, Max-Change: 0.00084\n",
            "EM cycles terminated after 500 iterations.\n",
            "\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h              F1     h2\n",
            "Item.1     0.774 0.5994\n",
            "Item.2     0.992 0.9838\n",
            "Item.3     0.774 0.5994\n",
            "Item.4     0.990 0.9808\n",
            "Item.5     0.985 0.9702\n",
            "Item.6     0.990 0.9808\n",
            "Item.7     0.988 0.9754\n",
            "Item.8     0.990 0.9808\n",
            "Item.9     0.992 0.9840\n",
            "Item.10    0.988 0.9754\n",
            "Item.11    0.988 0.9754\n",
            "Item.12    0.988 0.9754\n",
            "Item.13    0.988 0.9754\n",
            "Item.14    0.988 0.9754\n",
            "Item.15    0.990 0.9808\n",
            "Item.16    0.774 0.5994\n",
            "Item.17    0.997 0.9948\n",
            "Item.18    0.988 0.9754\n",
            "Item.19    0.990 0.9808\n",
            "Item.20    0.387 0.1499\n",
            "Item.21    0.990 0.9808\n",
            "Item.22    0.997 0.9945\n",
            "Item.23    0.774 0.5994\n",
            "Item.24    0.997 0.9948\n",
            "Item.25    0.988 0.9754\n",
            "Item.26    0.988 0.9754\n",
            "Item.27    0.988 0.9754\n",
            "Item.28    0.992 0.9840\n",
            "Item.29    0.990 0.9808\n",
            "Item.30    0.992 0.9838\n",
            "Item.31    0.999 0.9984\n",
            "Item.32    0.988 0.9754\n",
            "Item.33    0.997 0.9948\n",
            "Item.34    0.990 0.9808\n",
            "Item.35    0.990 0.9808\n",
            "Item.36    0.774 0.5994\n",
            "Item.37    0.988 0.9754\n",
            "Item.38    0.997 0.9948\n",
            "Item.39    0.988 0.9754\n",
            "Item.40    0.997 0.9948\n",
            "Item.41    0.387 0.1499\n",
            "Item.42    0.774 0.5994\n",
            "Item.43    0.990 0.9808\n",
            "Item.44    0.992 0.9838\n",
            "Item.45    0.992 0.9840\n",
            "Item.46    0.990 0.9808\n",
            "Item.47    0.997 0.9948\n",
            "Item.48    0.997 0.9948\n",
            "Item.49    0.985 0.9698\n",
            "Item.50    0.990 0.9808\n",
            "Item.51    0.995 0.9896\n",
            "Item.52    0.990 0.9808\n",
            "Item.53    0.997 0.9945\n",
            "Item.54    0.774 0.5994\n",
            "Item.55    0.999 0.9984\n",
            "Item.56    0.992 0.9840\n",
            "Item.57    0.990 0.9808\n",
            "Item.58    0.997 0.9948\n",
            "Item.59    0.997 0.9948\n",
            "Item.60    0.988 0.9754\n",
            "Item.61    0.988 0.9754\n",
            "Item.62    0.988 0.9754\n",
            "Item.63    0.990 0.9808\n",
            "Item.64    0.997 0.9945\n",
            "Item.65    0.387 0.1499\n",
            "Item.66    0.995 0.9896\n",
            "Item.67    0.997 0.9948\n",
            "Item.68    0.990 0.9808\n",
            "Item.69    0.988 0.9754\n",
            "Item.70    0.774 0.5994\n",
            "Item.71    0.990 0.9808\n",
            "Item.72    0.988 0.9754\n",
            "Item.73    0.774 0.5994\n",
            "Item.74    0.995 0.9896\n",
            "Item.75    0.988 0.9754\n",
            "Item.76    0.990 0.9808\n",
            "Item.77    0.990 0.9808\n",
            "Item.78    0.997 0.9948\n",
            "Item.79    0.995 0.9896\n",
            "Item.80    0.988 0.9754\n",
            "Item.81    0.985 0.9702\n",
            "Item.82    0.774 0.5994\n",
            "Item.83    0.988 0.9754\n",
            "Item.84    0.997 0.9945\n",
            "Item.85    0.997 0.9945\n",
            "Item.86    0.990 0.9808\n",
            "Item.87    0.988 0.9754\n",
            "Item.88    0.997 0.9948\n",
            "Item.89    0.990 0.9808\n",
            "Item.90    0.997 0.9945\n",
            "Item.91    0.505 0.2551\n",
            "Item.92    0.505 0.2551\n",
            "Item.93    0.997 0.9948\n",
            "Item.94    0.988 0.9754\n",
            "Item.95    0.774 0.5994\n",
            "Item.96    0.995 0.9896\n",
            "Item.97    0.988 0.9754\n",
            "Item.98    0.992 0.9840\n",
            "Item.99    0.774 0.5994\n",
            "Item.100   0.992 0.9840\n",
            "Item.101   0.985 0.9702\n",
            "Item.102   0.985 0.9702\n",
            "Item.103   0.985 0.9702\n",
            "Item.104   0.387 0.1499\n",
            "Item.105   0.988 0.9754\n",
            "Item.106   0.985 0.9702\n",
            "Item.107   0.985 0.9702\n",
            "Item.108   0.985 0.9698\n",
            "Item.109   0.985 0.9702\n",
            "Item.110   0.985 0.9702\n",
            "Item.111   0.985 0.9702\n",
            "Item.112   0.985 0.9702\n",
            "Item.113   0.985 0.9702\n",
            "Item.114   0.985 0.9709\n",
            "Item.115   0.985 0.9702\n",
            "Item.116   0.334 0.1114\n",
            "Item.117   0.985 0.9698\n",
            "Item.118   0.985 0.9702\n",
            "Item.119   0.985 0.9702\n",
            "Item.120   0.387 0.1499\n",
            "Item.121   0.985 0.9702\n",
            "Item.122   0.985 0.9702\n",
            "Item.123   0.985 0.9702\n",
            "Item.124   0.995 0.9896\n",
            "Item.125   0.985 0.9702\n",
            "Item.126   0.387 0.1499\n",
            "Item.127   0.985 0.9702\n",
            "Item.128   0.985 0.9702\n",
            "Item.129   0.995 0.9893\n",
            "Item.130   0.985 0.9702\n",
            "Item.131   0.988 0.9754\n",
            "Item.132   0.387 0.1499\n",
            "Item.133   0.999 0.9984\n",
            "Item.134   0.985 0.9702\n",
            "Item.135   0.985 0.9702\n",
            "Item.136   0.985 0.9702\n",
            "Item.137   0.985 0.9702\n",
            "Item.138   0.985 0.9702\n",
            "Item.139   0.245 0.0603\n",
            "Item.140   0.985 0.9702\n",
            "Item.141   0.985 0.9702\n",
            "Item.142   0.985 0.9702\n",
            "Item.143   0.985 0.9702\n",
            "Item.144   0.985 0.9698\n",
            "Item.145   0.985 0.9702\n",
            "Item.146   0.985 0.9698\n",
            "Item.147   0.985 0.9702\n",
            "Item.148   0.985 0.9702\n",
            "Item.149   0.985 0.9702\n",
            "Item.150   0.985 0.9702\n",
            "Item.151   0.985 0.9702\n",
            "Item.152   0.985 0.9702\n",
            "Item.153   0.995 0.9896\n",
            "Item.154   0.985 0.9702\n",
            "Item.155   0.985 0.9702\n",
            "Item.156   0.985 0.9702\n",
            "Item.157   0.985 0.9698\n",
            "Item.158   0.985 0.9702\n",
            "Item.159   0.985 0.9702\n",
            "Item.160   0.985 0.9702\n",
            "Item.161   0.999 0.9984\n",
            "Item.162   0.985 0.9702\n",
            "Item.163   0.985 0.9702\n",
            "Item.164   0.985 0.9702\n",
            "Item.165   0.985 0.9702\n",
            "Item.166   0.985 0.9698\n",
            "Item.167   0.985 0.9702\n",
            "Item.168   0.985 0.9702\n",
            "Item.169   0.985 0.9702\n",
            "Item.170   0.985 0.9698\n",
            "Item.171   0.985 0.9702\n",
            "Item.172   0.505 0.2551\n",
            "Item.173   0.985 0.9702\n",
            "Item.174   0.995 0.9896\n",
            "Item.175   0.985 0.9709\n",
            "Item.176   0.985 0.9702\n",
            "Item.177   0.985 0.9702\n",
            "Item.178   0.985 0.9702\n",
            "Item.179   0.985 0.9702\n",
            "Item.180   0.985 0.9702\n",
            "Item.181   0.985 0.9702\n",
            "Item.182   0.985 0.9702\n",
            "Item.183   0.985 0.9702\n",
            "Item.184   0.990 0.9808\n",
            "Item.185   0.985 0.9702\n",
            "Item.186   0.985 0.9702\n",
            "Item.187   0.985 0.9702\n",
            "Item.188   0.988 0.9754\n",
            "Item.189   0.985 0.9702\n",
            "Item.190   0.985 0.9702\n",
            "Item.191   0.985 0.9702\n",
            "Item.192   0.985 0.9702\n",
            "Item.193   0.985 0.9702\n",
            "Item.194   0.985 0.9697\n",
            "Item.195   0.985 0.9698\n",
            "Item.196   0.985 0.9702\n",
            "Item.197   0.985 0.9702\n",
            "Item.198   0.985 0.9702\n",
            "Item.199   0.985 0.9702\n",
            "Item.200   0.985 0.9702\n",
            "Item.201   0.992 0.9831\n",
            "Item.202   0.997 0.9948\n",
            "Item.203   0.985 0.9702\n",
            "Item.204   0.992 0.9831\n",
            "Item.205   0.990 0.9792\n",
            "Item.206   0.472 0.2224\n",
            "Item.207   0.990 0.9808\n",
            "Item.208   0.997 0.9948\n",
            "Item.209   0.995 0.9896\n",
            "Item.210   0.985 0.9702\n",
            "Item.211   0.992 0.9840\n",
            "Item.212   0.629 0.3960\n",
            "Item.213   0.990 0.9808\n",
            "Item.214   0.985 0.9702\n",
            "Item.215   0.990 0.9808\n",
            "Item.216   0.988 0.9754\n",
            "Item.217   0.985 0.9702\n",
            "Item.218   0.981 0.9628\n",
            "Item.219   0.997 0.9948\n",
            "Item.220   0.992 0.9840\n",
            "Item.221   0.990 0.9808\n",
            "Item.222   0.985 0.9702\n",
            "Item.223   0.774 0.5994\n",
            "Item.224   0.995 0.9893\n",
            "Item.225   0.992 0.9840\n",
            "Item.226   0.997 0.9948\n",
            "Item.227   0.985 0.9702\n",
            "Item.228   0.992 0.9836\n",
            "Item.229   0.985 0.9702\n",
            "Item.230   0.992 0.9840\n",
            "Item.231   0.990 0.9808\n",
            "Item.232   0.997 0.9948\n",
            "Item.233   0.990 0.9808\n",
            "Item.234   0.995 0.9896\n",
            "Item.235   0.985 0.9702\n",
            "Item.236   0.999 0.9984\n",
            "Item.237   0.992 0.9840\n",
            "Item.238   0.985 0.9702\n",
            "Item.239   0.629 0.3960\n",
            "Item.240  -0.997 0.9944\n",
            "Item.241   0.992 0.9840\n",
            "Item.242   0.992 0.9840\n",
            "Item.243   0.997 0.9948\n",
            "Item.244   0.990 0.9808\n",
            "Item.245   0.992 0.9840\n",
            "Item.246   0.985 0.9702\n",
            "Item.247   0.992 0.9831\n",
            "Item.248   0.992 0.9840\n",
            "Item.249   0.990 0.9808\n",
            "Item.250   0.985 0.9702\n",
            "Item.251   0.990 0.9808\n",
            "Item.252   0.990 0.9808\n",
            "Item.253   0.988 0.9754\n",
            "Item.254   0.995 0.9893\n",
            "Item.255   0.984 0.9676\n",
            "Item.256   0.997 0.9948\n",
            "Item.257   0.985 0.9702\n",
            "Item.258   0.997 0.9945\n",
            "Item.259   0.997 0.9948\n",
            "Item.260   0.995 0.9896\n",
            "Item.261   0.992 0.9840\n",
            "Item.262   0.997 0.9948\n",
            "Item.263   0.985 0.9702\n",
            "Item.264   0.995 0.9893\n",
            "Item.265   0.985 0.9702\n",
            "Item.266   0.999 0.9984\n",
            "Item.267   0.472 0.2224\n",
            "Item.268   0.992 0.9831\n",
            "Item.269   0.988 0.9752\n",
            "Item.270   0.985 0.9697\n",
            "Item.271   0.992 0.9840\n",
            "Item.272   0.990 0.9808\n",
            "Item.273   0.988 0.9752\n",
            "Item.274   0.985 0.9697\n",
            "Item.275   0.988 0.9754\n",
            "Item.276   0.988 0.9752\n",
            "Item.277   0.990 0.9808\n",
            "Item.278   0.985 0.9702\n",
            "Item.279   0.985 0.9702\n",
            "Item.280   0.997 0.9948\n",
            "Item.281   0.990 0.9808\n",
            "Item.282   0.992 0.9831\n",
            "Item.283   0.992 0.9838\n",
            "Item.284   0.999 0.9984\n",
            "Item.285   0.988 0.9754\n",
            "Item.286   0.985 0.9702\n",
            "Item.287   0.990 0.9792\n",
            "Item.288   0.995 0.9896\n",
            "Item.289   0.995 0.9893\n",
            "Item.290   0.990 0.9808\n",
            "Item.291   0.985 0.9702\n",
            "Item.292   0.985 0.9702\n",
            "Item.293   0.997 0.9948\n",
            "Item.294   0.774 0.5994\n",
            "Item.295   0.990 0.9808\n",
            "Item.296   0.990 0.9808\n",
            "Item.297   0.990 0.9808\n",
            "Item.298   0.992 0.9840\n",
            "Item.299   0.774 0.5994\n",
            "Item.300   0.992 0.9831\n",
            "Item.301   0.985 0.9702\n",
            "Item.302   0.997 0.9948\n",
            "Item.303  -0.996 0.9930\n",
            "Item.304   0.995 0.9893\n",
            "Item.305   0.997 0.9948\n",
            "Item.306   0.997 0.9948\n",
            "Item.307   0.988 0.9754\n",
            "Item.308   0.985 0.9702\n",
            "Item.309   0.629 0.3960\n",
            "Item.310   0.629 0.3960\n",
            "Item.311   0.988 0.9754\n",
            "Item.312   0.992 0.9838\n",
            "Item.313   0.985 0.9709\n",
            "Item.314   0.990 0.9808\n",
            "Item.315   0.995 0.9896\n",
            "Item.316   0.995 0.9896\n",
            "Item.317   0.997 0.9948\n",
            "Item.318   0.629 0.3960\n",
            "Item.319   0.997 0.9947\n",
            "Item.320   0.997 0.9947\n",
            "Item.321   0.990 0.9808\n",
            "Item.322   0.997 0.9948\n",
            "Item.323   0.472 0.2224\n",
            "Item.324   0.995 0.9893\n",
            "Item.325   0.472 0.2224\n",
            "Item.326  -0.997 0.9944\n",
            "Item.327   0.999 0.9983\n",
            "Item.328   0.985 0.9693\n",
            "Item.329   0.995 0.9896\n",
            "Item.330   0.999 0.9984\n",
            "Item.331   0.505 0.2551\n",
            "Item.332   0.334 0.1114\n",
            "Item.333   0.985 0.9697\n",
            "Item.334   0.985 0.9702\n",
            "Item.335   0.988 0.9754\n",
            "Item.336   0.985 0.9702\n",
            "Item.337   0.985 0.9698\n",
            "Item.338   0.472 0.2224\n",
            "Item.339   0.988 0.9754\n",
            "Item.340   0.988 0.9754\n",
            "Item.341   0.985 0.9698\n",
            "Item.342  -0.996 0.9930\n",
            "Item.343   0.990 0.9808\n",
            "Item.344   0.472 0.2224\n",
            "Item.345   0.990 0.9808\n",
            "Item.346   0.988 0.9754\n",
            "Item.347   0.629 0.3960\n",
            "Item.348   0.988 0.9754\n",
            "Item.349   0.985 0.9702\n",
            "Item.350   0.985 0.9702\n",
            "Item.351   0.985 0.9702\n",
            "Item.352   0.988 0.9754\n",
            "Item.353   0.472 0.2224\n",
            "Item.354   0.985 0.9702\n",
            "Item.355   0.985 0.9698\n",
            "Item.356   0.985 0.9702\n",
            "Item.357   0.472 0.2224\n",
            "Item.358   0.990 0.9808\n",
            "Item.359   0.629 0.3960\n",
            "Item.360   0.988 0.9754\n",
            "Item.361   0.985 0.9702\n",
            "Item.362   0.990 0.9808\n",
            "Item.363   0.472 0.2224\n",
            "Item.364   0.988 0.9754\n",
            "Item.365   0.990 0.9808\n",
            "Item.366   0.999 0.9984\n",
            "Item.367   0.985 0.9697\n",
            "Item.368   0.988 0.9754\n",
            "Item.369   0.985 0.9697\n",
            "Item.370   0.985 0.9693\n",
            "Item.371   0.334 0.1114\n",
            "Item.372   0.985 0.9697\n",
            "Item.373   0.990 0.9808\n",
            "Item.374   0.985 0.9697\n",
            "Item.375   0.982 0.9636\n",
            "Item.376   0.985 0.9697\n",
            "Item.377   0.990 0.9808\n",
            "Item.378   0.985 0.9698\n",
            "Item.379   0.988 0.9754\n",
            "Item.380   0.988 0.9754\n",
            "Item.381  -0.996 0.9930\n",
            "Item.382   0.629 0.3960\n",
            "Item.383   0.334 0.1114\n",
            "Item.384   0.988 0.9754\n",
            "Item.385   0.985 0.9702\n",
            "Item.386   0.334 0.1114\n",
            "Item.387   0.988 0.9754\n",
            "Item.388   0.988 0.9754\n",
            "Item.389   0.988 0.9754\n",
            "Item.390   0.985 0.9702\n",
            "Item.391   0.997 0.9948\n",
            "Item.392   0.985 0.9698\n",
            "Item.393   0.985 0.9698\n",
            "Item.394   0.985 0.9702\n",
            "Item.395   0.988 0.9754\n",
            "Item.396   0.985 0.9702\n",
            "Item.397   0.988 0.9754\n",
            "Item.398   0.990 0.9808\n",
            "Item.399   0.985 0.9702\n",
            "Item.400   0.472 0.2224\n",
            "Item.401   0.992 0.9831\n",
            "Item.402   0.988 0.9754\n",
            "Item.403   0.999 0.9983\n",
            "Item.404   0.988 0.9754\n",
            "Item.405   0.985 0.9702\n",
            "Item.406   0.985 0.9702\n",
            "Item.407   0.992 0.9840\n",
            "Item.408   0.629 0.3960\n",
            "Item.409   0.774 0.5994\n",
            "Item.410   0.984 0.9679\n",
            "Item.411   0.982 0.9649\n",
            "Item.412   0.988 0.9754\n",
            "Item.413   0.988 0.9754\n",
            "Item.414   0.985 0.9702\n",
            "Item.415   0.629 0.3960\n",
            "Item.416   0.982 0.9635\n",
            "Item.417   0.984 0.9679\n",
            "Item.418   0.988 0.9754\n",
            "Item.419   0.982 0.9636\n",
            "Item.420   0.988 0.9754\n",
            "Item.421   0.988 0.9754\n",
            "Item.422   0.985 0.9702\n",
            "Item.423   0.985 0.9698\n",
            "Item.424   0.984 0.9676\n",
            "Item.425   0.629 0.3960\n",
            "Item.426   0.988 0.9754\n",
            "Item.427   0.988 0.9754\n",
            "Item.428   0.472 0.2224\n",
            "Item.429   0.988 0.9754\n",
            "Item.430   0.985 0.9698\n",
            "Item.431   0.988 0.9754\n",
            "Item.432   0.988 0.9754\n",
            "Item.433   0.997 0.9947\n",
            "Item.434   0.985 0.9697\n",
            "Item.435   0.988 0.9754\n",
            "Item.436   0.999 0.9983\n",
            "Item.437   0.629 0.3960\n",
            "Item.438   0.988 0.9754\n",
            "Item.439   0.988 0.9754\n",
            "Item.440   0.988 0.9754\n",
            "Item.441   0.985 0.9702\n",
            "Item.442   0.985 0.9698\n",
            "Item.443   0.387 0.1499\n",
            "Item.444   0.472 0.2224\n",
            "Item.445   0.988 0.9754\n",
            "Item.446   0.988 0.9754\n",
            "Item.447   0.997 0.9947\n",
            "Item.448   0.992 0.9840\n",
            "Item.449   0.988 0.9754\n",
            "Item.450   0.988 0.9754\n",
            "Item.451   0.985 0.9702\n",
            "Item.452   0.985 0.9697\n",
            "Item.453   0.985 0.9697\n",
            "Item.454   0.985 0.9702\n",
            "Item.455   0.629 0.3960\n",
            "Item.456   0.988 0.9754\n",
            "Item.457   0.999 0.9984\n",
            "Item.458   0.988 0.9754\n",
            "Item.459   0.985 0.9702\n",
            "Item.460   0.472 0.2224\n",
            "Item.461   0.988 0.9754\n",
            "Item.462   0.988 0.9754\n",
            "Item.463   0.985 0.9698\n",
            "Item.464   0.985 0.9702\n",
            "Item.465   0.988 0.9754\n",
            "Item.466   0.505 0.2551\n",
            "Item.467   0.995 0.9896\n",
            "Item.468   0.988 0.9754\n",
            "Item.469   0.995 0.9893\n",
            "Item.470   0.988 0.9754\n",
            "Item.471   0.988 0.9754\n",
            "Item.472   0.992 0.9831\n",
            "Item.473   0.472 0.2224\n",
            "Item.474   0.988 0.9754\n",
            "Item.475   0.988 0.9754\n",
            "Item.476   0.984 0.9679\n",
            "Item.477   0.997 0.9947\n",
            "Item.478   0.985 0.9697\n",
            "Item.479   0.990 0.9792\n",
            "Item.480   0.334 0.1114\n",
            "Item.481  -0.996 0.9930\n",
            "Item.482   0.988 0.9754\n",
            "Item.483   0.387 0.1499\n",
            "Item.484   0.774 0.5994\n",
            "Item.485   0.988 0.9754\n",
            "Item.486   0.985 0.9697\n",
            "Item.487   0.999 0.9984\n",
            "Item.488   0.985 0.9693\n",
            "Item.489   0.988 0.9754\n",
            "Item.490   0.988 0.9754\n",
            "Item.491   0.988 0.9754\n",
            "Item.492   0.984 0.9676\n",
            "Item.493   0.988 0.9754\n",
            "Item.494   0.992 0.9831\n",
            "Item.495   0.988 0.9754\n",
            "Item.496   0.985 0.9709\n",
            "Item.497   0.990 0.9792\n",
            "Item.498   0.984 0.9679\n",
            "Item.499   0.990 0.9808\n",
            "Item.500   0.988 0.9754\n",
            "Item.501   0.988 0.9754\n",
            "Item.502   0.990 0.9808\n",
            "Item.503   0.990 0.9808\n",
            "Item.504   0.990 0.9808\n",
            "Item.505   0.629 0.3960\n",
            "Item.506   0.990 0.9808\n",
            "Item.507   0.988 0.9754\n",
            "Item.508   0.985 0.9702\n",
            "Item.509   0.387 0.1499\n",
            "Item.510   0.999 0.9984\n",
            "Item.511   0.629 0.3960\n",
            "Item.512   0.629 0.3960\n",
            "Item.513   0.995 0.9896\n",
            "Item.514   0.990 0.9808\n",
            "Item.515   0.988 0.9754\n",
            "Item.516   0.990 0.9808\n",
            "Item.517   0.334 0.1114\n",
            "Item.518   0.981 0.9628\n",
            "Item.519   0.990 0.9808\n",
            "Item.520   0.985 0.9698\n",
            "Item.521   0.985 0.9702\n",
            "Item.522   0.990 0.9808\n",
            "Item.523   0.990 0.9808\n",
            "Item.524   0.387 0.1499\n",
            "Item.525   0.990 0.9808\n",
            "Item.526   0.990 0.9808\n",
            "Item.527   0.985 0.9702\n",
            "Item.528   0.985 0.9702\n",
            "Item.529   0.990 0.9808\n",
            "Item.530  -0.996 0.9930\n",
            "Item.531   0.985 0.9702\n",
            "Item.532   0.990 0.9808\n",
            "Item.533   0.990 0.9808\n",
            "Item.534   0.985 0.9702\n",
            "Item.535   0.985 0.9702\n",
            "Item.536   0.990 0.9808\n",
            "Item.537   0.629 0.3960\n",
            "Item.538   0.990 0.9808\n",
            "Item.539   0.629 0.3960\n",
            "Item.540   0.629 0.3960\n",
            "Item.541   0.990 0.9808\n",
            "Item.542   0.999 0.9984\n",
            "Item.543   0.992 0.9831\n",
            "Item.544   0.629 0.3960\n",
            "Item.545   0.990 0.9808\n",
            "Item.546   0.985 0.9698\n",
            "Item.547   0.992 0.9831\n",
            "Item.548   0.992 0.9831\n",
            "Item.549   0.988 0.9754\n",
            "Item.550   0.988 0.9754\n",
            "Item.551   0.629 0.3960\n",
            "Item.552   0.990 0.9808\n",
            "Item.553   0.985 0.9697\n",
            "Item.554   0.985 0.9698\n",
            "Item.555   0.472 0.2224\n",
            "Item.556   0.990 0.9808\n",
            "Item.557   0.990 0.9808\n",
            "Item.558   0.629 0.3960\n",
            "Item.559   0.985 0.9702\n",
            "Item.560   0.990 0.9808\n",
            "Item.561   0.990 0.9792\n",
            "Item.562   0.985 0.9709\n",
            "Item.563   0.990 0.9808\n",
            "Item.564   0.629 0.3960\n",
            "Item.565   0.990 0.9808\n",
            "Item.566   0.990 0.9808\n",
            "Item.567   0.999 0.9984\n",
            "Item.568   0.990 0.9808\n",
            "Item.569   0.990 0.9808\n",
            "Item.570   0.472 0.2224\n",
            "Item.571   0.990 0.9808\n",
            "Item.572   0.990 0.9808\n",
            "Item.573   0.999 0.9984\n",
            "Item.574   0.629 0.3960\n",
            "Item.575   0.999 0.9984\n",
            "Item.576   0.990 0.9808\n",
            "Item.577   0.988 0.9754\n",
            "Item.578   0.999 0.9983\n",
            "Item.579   0.990 0.9808\n",
            "Item.580   0.990 0.9808\n",
            "Item.581   0.629 0.3960\n",
            "Item.582   0.992 0.9831\n",
            "Item.583   0.997 0.9948\n",
            "Item.584   0.997 0.9948\n",
            "Item.585   0.990 0.9808\n",
            "Item.586   0.990 0.9808\n",
            "Item.587   0.990 0.9808\n",
            "Item.588   0.992 0.9831\n",
            "Item.589   0.990 0.9808\n",
            "Item.590   0.988 0.9754\n",
            "Item.591   0.505 0.2551\n",
            "Item.592   0.990 0.9808\n",
            "Item.593   0.985 0.9702\n",
            "Item.594   0.995 0.9896\n",
            "Item.595   0.997 0.9948\n",
            "Item.596   0.990 0.9808\n",
            "Item.597   0.985 0.9698\n",
            "Item.598   0.988 0.9754\n",
            "Item.599   0.992 0.9840\n",
            "Item.600   0.999 0.9984\n",
            "Item.601   0.995 0.9893\n",
            "Item.602   0.992 0.9840\n",
            "Item.603   0.995 0.9896\n",
            "Item.604   0.999 0.9984\n",
            "Item.605   0.992 0.9840\n",
            "Item.606   0.995 0.9896\n",
            "Item.607   0.995 0.9896\n",
            "Item.608   0.992 0.9840\n",
            "Item.609   0.995 0.9893\n",
            "Item.610   0.992 0.9840\n",
            "Item.611   0.995 0.9896\n",
            "Item.612   0.992 0.9840\n",
            "Item.613   0.995 0.9896\n",
            "Item.614   0.995 0.9896\n",
            "Item.615   0.992 0.9840\n",
            "Item.616   0.246 0.0605\n",
            "Item.617   0.999 0.9984\n",
            "Item.618   0.992 0.9840\n",
            "Item.619   0.992 0.9840\n",
            "Item.620   0.992 0.9840\n",
            "Item.621   0.990 0.9808\n",
            "Item.622   0.992 0.9838\n",
            "Item.623   0.992 0.9840\n",
            "Item.624   0.992 0.9840\n",
            "Item.625   0.334 0.1114\n",
            "Item.626   0.997 0.9948\n",
            "Item.627   0.995 0.9896\n",
            "Item.628   0.995 0.9893\n",
            "Item.629   0.995 0.9896\n",
            "Item.630   0.995 0.9896\n",
            "Item.631   0.246 0.0603\n",
            "Item.632   0.995 0.9896\n",
            "Item.633   0.992 0.9840\n",
            "Item.634   0.995 0.9893\n",
            "Item.635   0.992 0.9840\n",
            "Item.636   0.995 0.9893\n",
            "Item.637   0.995 0.9896\n",
            "Item.638   0.992 0.9840\n",
            "Item.639   0.995 0.9893\n",
            "Item.640   0.995 0.9896\n",
            "Item.641   0.992 0.9840\n",
            "Item.642   0.995 0.9896\n",
            "Item.643   0.995 0.9896\n",
            "Item.644   0.995 0.9893\n",
            "Item.645   0.985 0.9693\n",
            "Item.646   0.774 0.5994\n",
            "Item.647   0.995 0.9896\n",
            "Item.648   0.995 0.9896\n",
            "Item.649   0.992 0.9838\n",
            "Item.650   0.995 0.9896\n",
            "Item.651   0.774 0.5994\n",
            "Item.652   0.995 0.9893\n",
            "Item.653   0.995 0.9896\n",
            "Item.654   0.774 0.5994\n",
            "Item.655   0.995 0.9896\n",
            "Item.656   0.774 0.5994\n",
            "Item.657   0.246 0.0603\n",
            "Item.658   0.992 0.9840\n",
            "Item.659   0.995 0.9896\n",
            "Item.660   0.999 0.9983\n",
            "Item.661   0.995 0.9896\n",
            "Item.662   0.992 0.9840\n",
            "Item.663   0.992 0.9838\n",
            "Item.664   0.774 0.5994\n",
            "Item.665   0.995 0.9896\n",
            "Item.666   0.505 0.2551\n",
            "Item.667   0.774 0.5994\n",
            "Item.668   0.999 0.9984\n",
            "Item.669   0.992 0.9840\n",
            "Item.670   0.995 0.9896\n",
            "Item.671   0.246 0.0604\n",
            "Item.672   0.992 0.9840\n",
            "Item.673   0.995 0.9896\n",
            "Item.674   0.992 0.9840\n",
            "Item.675   0.992 0.9840\n",
            "Item.676   0.992 0.9831\n",
            "Item.677   0.992 0.9840\n",
            "Item.678   0.992 0.9840\n",
            "Item.679   0.992 0.9838\n",
            "Item.680   0.774 0.5994\n",
            "Item.681   0.997 0.9945\n",
            "Item.682   0.992 0.9838\n",
            "Item.683   0.774 0.5994\n",
            "Item.684   0.997 0.9945\n",
            "Item.685   0.995 0.9896\n",
            "Item.686   0.995 0.9896\n",
            "Item.687   0.995 0.9896\n",
            "Item.688   0.992 0.9840\n",
            "Item.689   0.246 0.0604\n",
            "Item.690   0.992 0.9831\n",
            "Item.691   0.992 0.9840\n",
            "Item.692  -0.996 0.9930\n",
            "Item.693   0.992 0.9838\n",
            "Item.694   0.995 0.9893\n",
            "Item.695   0.774 0.5994\n",
            "Item.696   0.995 0.9896\n",
            "Item.697  -0.996 0.9930\n",
            "Item.698   0.995 0.9896\n",
            "Item.699   0.774 0.5994\n",
            "Item.700   0.992 0.9840\n",
            "Item.701   0.985 0.9702\n",
            "Item.702   0.988 0.9754\n",
            "Item.703   0.985 0.9702\n",
            "Item.704   0.985 0.9702\n",
            "Item.705   0.985 0.9702\n",
            "Item.706   0.985 0.9698\n",
            "Item.707   0.985 0.9702\n",
            "Item.708   0.985 0.9702\n",
            "Item.709   0.988 0.9754\n",
            "Item.710   0.995 0.9893\n",
            "Item.711   0.985 0.9702\n",
            "Item.712   0.985 0.9702\n",
            "Item.713   0.985 0.9702\n",
            "Item.714   0.985 0.9702\n",
            "Item.715   0.985 0.9702\n",
            "Item.716   0.472 0.2224\n",
            "Item.717   0.985 0.9702\n",
            "Item.718   0.985 0.9702\n",
            "Item.719   0.985 0.9702\n",
            "Item.720   0.985 0.9709\n",
            "Item.721   0.985 0.9702\n",
            "Item.722   0.985 0.9702\n",
            "Item.723   0.985 0.9702\n",
            "Item.724   0.988 0.9754\n",
            "Item.725   0.985 0.9702\n",
            "Item.726   0.334 0.1114\n",
            "Item.727   0.985 0.9702\n",
            "Item.728   0.985 0.9702\n",
            "Item.729   0.985 0.9702\n",
            "Item.730   0.985 0.9702\n",
            "Item.731   0.988 0.9754\n",
            "Item.732   0.985 0.9702\n",
            "Item.733   0.985 0.9694\n",
            "Item.734   0.985 0.9702\n",
            "Item.735   0.985 0.9698\n",
            "Item.736   0.985 0.9702\n",
            "Item.737   0.990 0.9808\n",
            "Item.738   0.985 0.9698\n",
            "Item.739   0.985 0.9702\n",
            "Item.740   0.988 0.9754\n",
            "Item.741   0.988 0.9754\n",
            "Item.742   0.985 0.9702\n",
            "Item.743   0.985 0.9702\n",
            "Item.744   0.985 0.9702\n",
            "Item.745   0.985 0.9702\n",
            "Item.746   0.985 0.9702\n",
            "Item.747   0.985 0.9702\n",
            "Item.748   0.985 0.9702\n",
            "Item.749   0.985 0.9702\n",
            "Item.750   0.985 0.9698\n",
            "Item.751   0.985 0.9702\n",
            "Item.752   0.985 0.9698\n",
            "Item.753   0.988 0.9754\n",
            "Item.754   0.985 0.9702\n",
            "Item.755   0.985 0.9702\n",
            "Item.756   0.985 0.9702\n",
            "Item.757   0.988 0.9754\n",
            "Item.758   0.985 0.9702\n",
            "Item.759   0.988 0.9754\n",
            "Item.760   0.985 0.9702\n",
            "Item.761   0.985 0.9702\n",
            "Item.762   0.387 0.1499\n",
            "Item.763   0.985 0.9702\n",
            "Item.764   0.988 0.9754\n",
            "Item.765   0.985 0.9702\n",
            "Item.766   0.985 0.9702\n",
            "Item.767   0.985 0.9702\n",
            "Item.768   0.985 0.9702\n",
            "Item.769   0.505 0.2551\n",
            "Item.770   0.985 0.9702\n",
            "Item.771   0.985 0.9698\n",
            "Item.772   0.985 0.9702\n",
            "Item.773   0.985 0.9702\n",
            "Item.774   0.985 0.9702\n",
            "Item.775   0.985 0.9702\n",
            "Item.776   0.985 0.9702\n",
            "Item.777   0.985 0.9697\n",
            "Item.778   0.985 0.9702\n",
            "Item.779   0.985 0.9702\n",
            "Item.780   0.985 0.9702\n",
            "Item.781   0.985 0.9702\n",
            "Item.782   0.988 0.9754\n",
            "Item.783   0.985 0.9702\n",
            "Item.784   0.985 0.9702\n",
            "Item.785   0.985 0.9698\n",
            "Item.786   0.985 0.9702\n",
            "Item.787   0.985 0.9702\n",
            "Item.788   0.985 0.9702\n",
            "Item.789   0.988 0.9754\n",
            "Item.790   0.985 0.9702\n",
            "Item.791   0.985 0.9702\n",
            "Item.792   0.985 0.9702\n",
            "Item.793   0.988 0.9754\n",
            "Item.794   0.985 0.9702\n",
            "Item.795   0.985 0.9702\n",
            "Item.796   0.985 0.9702\n",
            "Item.797   0.985 0.9702\n",
            "Item.798   0.985 0.9702\n",
            "Item.799   0.985 0.9702\n",
            "Item.800   0.985 0.9702\n",
            "Item.801   0.985 0.9702\n",
            "Item.802   0.995 0.9896\n",
            "Item.803   0.985 0.9702\n",
            "Item.804   0.990 0.9808\n",
            "Item.805   0.985 0.9702\n",
            "Item.806   0.505 0.2551\n",
            "Item.807   0.985 0.9698\n",
            "Item.808   0.985 0.9702\n",
            "Item.809   0.985 0.9702\n",
            "Item.810   0.985 0.9698\n",
            "Item.811   0.985 0.9698\n",
            "Item.812   0.985 0.9697\n",
            "Item.813   0.985 0.9702\n",
            "Item.814   0.985 0.9698\n",
            "Item.815   0.985 0.9702\n",
            "Item.816  -0.996 0.9930\n",
            "Item.817   0.988 0.9754\n",
            "Item.818   0.985 0.9702\n",
            "Item.819   0.985 0.9702\n",
            "Item.820   0.982 0.9649\n",
            "Item.821   0.387 0.1499\n",
            "Item.822   0.387 0.1499\n",
            "Item.823   0.985 0.9702\n",
            "Item.824   0.985 0.9702\n",
            "Item.825   0.985 0.9702\n",
            "Item.826   0.985 0.9702\n",
            "Item.827   0.472 0.2224\n",
            "Item.828   0.985 0.9702\n",
            "Item.829   0.985 0.9702\n",
            "Item.830   0.988 0.9754\n",
            "Item.831   0.995 0.9896\n",
            "Item.832   0.985 0.9702\n",
            "Item.833   0.985 0.9702\n",
            "Item.834   0.985 0.9702\n",
            "Item.835   0.387 0.1499\n",
            "Item.836   0.988 0.9754\n",
            "Item.837   0.985 0.9702\n",
            "Item.838   0.985 0.9702\n",
            "Item.839   0.985 0.9702\n",
            "Item.840   0.985 0.9702\n",
            "Item.841   0.985 0.9702\n",
            "Item.842   0.985 0.9702\n",
            "Item.843   0.985 0.9702\n",
            "Item.844   0.985 0.9702\n",
            "Item.845   0.985 0.9702\n",
            "Item.846   0.985 0.9698\n",
            "Item.847   0.990 0.9808\n",
            "Item.848   0.985 0.9702\n",
            "Item.849   0.985 0.9702\n",
            "Item.850   0.985 0.9698\n",
            "Item.851   0.629 0.3960\n",
            "Item.852   0.990 0.9808\n",
            "Item.853   0.985 0.9702\n",
            "Item.854   0.985 0.9702\n",
            "Item.855   0.988 0.9754\n",
            "Item.856   0.985 0.9702\n",
            "Item.857   0.985 0.9702\n",
            "Item.858   0.629 0.3960\n",
            "Item.859   0.246 0.0603\n",
            "Item.860   0.990 0.9808\n",
            "Item.861   0.985 0.9702\n",
            "Item.862   0.988 0.9754\n",
            "Item.863   0.988 0.9754\n",
            "Item.864   0.992 0.9831\n",
            "Item.865   0.985 0.9702\n",
            "Item.866   0.985 0.9702\n",
            "Item.867   0.985 0.9702\n",
            "Item.868   0.990 0.9808\n",
            "Item.869   0.985 0.9698\n",
            "Item.870   0.999 0.9983\n",
            "Item.871   0.985 0.9702\n",
            "Item.872   0.985 0.9702\n",
            "Item.873   0.985 0.9702\n",
            "Item.874   0.985 0.9702\n",
            "Item.875   0.985 0.9702\n",
            "Item.876   0.992 0.9831\n",
            "Item.877   0.985 0.9698\n",
            "Item.878   0.985 0.9702\n",
            "Item.879  -0.997 0.9944\n",
            "Item.880   0.387 0.1499\n",
            "Item.881   0.988 0.9754\n",
            "Item.882   0.985 0.9702\n",
            "Item.883   0.985 0.9702\n",
            "Item.884   0.995 0.9896\n",
            "Item.885   0.985 0.9698\n",
            "Item.886   0.985 0.9702\n",
            "Item.887   0.334 0.1114\n",
            "Item.888   0.985 0.9698\n",
            "Item.889   0.985 0.9702\n",
            "Item.890   0.985 0.9702\n",
            "Item.891   0.985 0.9702\n",
            "Item.892   0.988 0.9754\n",
            "Item.893   0.985 0.9702\n",
            "Item.894   0.988 0.9754\n",
            "Item.895   0.985 0.9702\n",
            "Item.896   0.990 0.9808\n",
            "Item.897   0.985 0.9702\n",
            "Item.898   0.985 0.9702\n",
            "Item.899   0.985 0.9702\n",
            "Item.900   0.992 0.9831\n",
            "Item.901   0.985 0.9702\n",
            "Item.902   0.999 0.9984\n",
            "Item.903   0.774 0.5994\n",
            "Item.904   0.985 0.9702\n",
            "Item.905   0.988 0.9754\n",
            "Item.906   0.988 0.9754\n",
            "Item.907   0.995 0.9896\n",
            "Item.908   0.985 0.9702\n",
            "Item.909   0.999 0.9983\n",
            "Item.910   0.997 0.9948\n",
            "Item.911   0.985 0.9702\n",
            "Item.912   0.985 0.9702\n",
            "Item.913   0.997 0.9948\n",
            "Item.914   0.997 0.9948\n",
            "Item.915   0.985 0.9702\n",
            "Item.916   0.985 0.9702\n",
            "Item.917   0.985 0.9702\n",
            "Item.918   0.988 0.9754\n",
            "Item.919   0.992 0.9840\n",
            "Item.920   0.988 0.9754\n",
            "Item.921   0.985 0.9702\n",
            "Item.922   0.985 0.9702\n",
            "Item.923   0.988 0.9754\n",
            "Item.924   0.985 0.9702\n",
            "Item.925   0.985 0.9702\n",
            "Item.926   0.988 0.9754\n",
            "Item.927   0.988 0.9752\n",
            "Item.928   0.988 0.9754\n",
            "Item.929   0.988 0.9754\n",
            "Item.930   0.985 0.9702\n",
            "Item.931   0.988 0.9754\n",
            "Item.932   0.985 0.9702\n",
            "Item.933   0.999 0.9984\n",
            "Item.934   0.988 0.9754\n",
            "Item.935   0.985 0.9702\n",
            "Item.936   0.985 0.9702\n",
            "Item.937   0.988 0.9754\n",
            "Item.938   0.985 0.9702\n",
            "Item.939   0.985 0.9702\n",
            "Item.940   0.997 0.9948\n",
            "Item.941   0.988 0.9754\n",
            "Item.942   0.988 0.9754\n",
            "Item.943   0.988 0.9754\n",
            "Item.944   0.629 0.3960\n",
            "Item.945   0.985 0.9702\n",
            "Item.946   0.985 0.9702\n",
            "Item.947   0.988 0.9754\n",
            "Item.948   0.985 0.9702\n",
            "Item.949   0.985 0.9702\n",
            "Item.950   0.988 0.9754\n",
            "Item.951   0.997 0.9948\n",
            "Item.952   0.988 0.9754\n",
            "Item.953   0.997 0.9948\n",
            "Item.954   0.997 0.9948\n",
            "Item.955   0.988 0.9754\n",
            "Item.956   0.999 0.9984\n",
            "Item.957   0.999 0.9984\n",
            "Item.958   0.985 0.9702\n",
            "Item.959   0.988 0.9754\n",
            "Item.960   0.985 0.9702\n",
            "Item.961   0.985 0.9702\n",
            "Item.962   0.999 0.9984\n",
            "Item.963   0.988 0.9754\n",
            "Item.964   0.985 0.9702\n",
            "Item.965   0.629 0.3960\n",
            "Item.966   0.999 0.9984\n",
            "Item.967   0.990 0.9808\n",
            "Item.968   0.997 0.9948\n",
            "Item.969   0.985 0.9702\n",
            "Item.970   0.999 0.9984\n",
            "Item.971   0.999 0.9984\n",
            "Item.972   0.985 0.9702\n",
            "Item.973   0.988 0.9754\n",
            "Item.974   0.985 0.9702\n",
            "Item.975   0.988 0.9754\n",
            "Item.976   0.999 0.9984\n",
            "Item.977   0.985 0.9702\n",
            "Item.978   0.985 0.9702\n",
            "Item.979   0.774 0.5994\n",
            "Item.980   0.988 0.9754\n",
            "Item.981   0.985 0.9702\n",
            "Item.982   0.995 0.9896\n",
            "Item.983   0.985 0.9702\n",
            "Item.984   0.985 0.9702\n",
            "Item.985   0.995 0.9896\n",
            "Item.986   0.995 0.9896\n",
            "Item.987   0.997 0.9948\n",
            "Item.988   0.997 0.9948\n",
            "Item.989   0.992 0.9840\n",
            "Item.990   0.990 0.9808\n",
            "Item.991   0.988 0.9754\n",
            "Item.992   0.999 0.9984\n",
            "Item.993   0.988 0.9754\n",
            "Item.994   0.387 0.1499\n",
            "Item.995   0.988 0.9754\n",
            "Item.996   0.988 0.9754\n",
            "Item.997   0.990 0.9808\n",
            "Item.998   0.990 0.9808\n",
            "Item.999   0.988 0.9754\n",
            "Item.1000  0.985 0.9702\n",
            "\n",
            "SS loadings:  901 \n",
            "Proportion Var:  0.901 \n",
            "\n",
            "Factor correlations: \n",
            "\n",
            "   F1\n",
            "F1  1\n",
            "\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25hnull device \n",
            "          1 \n",
            "\u001b[?25h\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pbyw1y8BBiYa"
      },
      "source": [
        "coef = pd.read_csv('/content/coef.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbU9XtbXBn6p"
      },
      "source": [
        "def formatar(coef): \n",
        "  nitens = 1000\n",
        "  ncoef = 4\n",
        "  totalvalues = nitens * ncoef\n",
        "  \n",
        "  a = []\n",
        "  for i in range(0, totalvalues, 4):\n",
        "    a.append(coef.iloc[i][1]) \n",
        "  b = []\n",
        "  for i in range(1, totalvalues, 4):\n",
        "    b.append(coef.iloc[i][1]) \n",
        "  c = []\n",
        "  for i in range(2, totalvalues, 4):\n",
        "    c.append(coef.iloc[i][1])\n",
        "  d = [] \n",
        "  for i in range(3, totalvalues, 4):\n",
        "    d.append(coef.iloc[i][1]) \n",
        "\n",
        "  df = pd.DataFrame({'itens': range(1, nitens + 1 ),\n",
        "                   'a': a,\n",
        "                   'b': b,\n",
        "                   'c': c,\n",
        "                   'd': d\n",
        "                   })\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z94XWneyBro7"
      },
      "source": [
        "df = formatar(coef)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPMDUmNb9jKr"
      },
      "source": [
        "df.to_csv('/content/idx.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "RKgHD5QABvnJ",
        "outputId": "4fa409a7-0d74-4f57-f0af-76948a30d015"
      },
      "source": [
        "dfa_ordenado = df.sort_values(by='a', ascending=False)\n",
        "dfb_ordenado = df.sort_values(by='b', ascending=False)\n",
        "dfc_ordenado = df.sort_values(by='c', ascending=False)\n",
        "\n",
        "dfc_ordenado.loc[(dfc_ordenado['itens'] == 481)]\n",
        "#dfa_ordenado.head(5)\n",
        "#dfa_ordenado.loc[(dfb_ordenado['itens'] > 7) & (dfb_ordenado['itens'] < 50)].head(50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>itens</th>\n",
              "      <th>a</th>\n",
              "      <th>b</th>\n",
              "      <th>c</th>\n",
              "      <th>d</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>480</th>\n",
              "      <td>481</td>\n",
              "      <td>-20.262073</td>\n",
              "      <td>0.074802</td>\n",
              "      <td>0.25001</td>\n",
              "      <td>0.499996</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     itens          a         b        c         d\n",
              "480    481 -20.262073  0.074802  0.25001  0.499996"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CUqyj0UDu79",
        "outputId": "3265afea-f926-49cf-fc8f-1e3ef815ef18"
      },
      "source": [
        " print(\"idxmaisa: \", idx[570])\n",
        "print(\"idxmaisb: \", idx[628])\n",
        "print(\"idxmaisc:\", idx[480])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "idxmaisa:  4181\n",
            "idxmaisb:  622\n",
            "idxmaisc: 5397\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_YwRyCJLoA5",
        "outputId": "6609ea12-8725-4171-93c3-aebd6954cfdd"
      },
      "source": [
        "idx_maisdificeis = np.array(dfb_ordenado['itens'][:30])\n",
        "idx_maisdiscriminantes = np.array(dfa_ordenado['itens'][:30])\n",
        "idx_chutes = np.array(dfc_ordenado['itens'][:30])\n",
        "\n",
        "dfidx = pd.DataFrame({ 'mais dificeis': idx_maisdificeis,\n",
        "                      'mais discriminantes': idx_maisdiscriminantes,\n",
        "                      'chutes': idx_chutes\n",
        "    \n",
        "})\n",
        "\n",
        "print(dfidx)\n",
        "dfidx.to_csv('/content/idx.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   mais dificeis  mais discriminantes  chutes\n",
            "0             12                    6     124\n",
            "1              9                   28     147\n",
            "2             97                   48     175\n",
            "3             91                   72      12\n",
            "4             78                   25      90\n",
            "5            183                   77     200\n",
            "6            175                   93     114\n",
            "7             20                   17     171\n",
            "8            186                    3     130\n",
            "9             55                   20     122\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1YR7tQTOId_",
        "outputId": "e05f6e4d-5bb0-47b0-e9c3-c5ca695b8858"
      },
      "source": [
        "idx_maisdificeis"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 6, 28, 48, 72, 25, 77, 93, 17,  3, 20])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    }
  ]
}